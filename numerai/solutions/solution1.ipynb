{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numerapi import NumerAPI\n",
    "import random\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import save_model, load_model, neutralize, get_biggest_change_features, validation_metrics, download_data\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import (\n",
    "    feature_extraction, feature_selection, decomposition, linear_model,\n",
    "    model_selection, metrics, svm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'era' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8fdc84b91bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numerai_training_data.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mera\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'era' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_parquet('numerai_training_data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2412105, 1073)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_data['era'] = train_data['era'].astype(int)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_dichasial_hammier_spawner', 'feature_rheumy_epistemic_prancer', 'feature_pert_performative_hormuz', 'feature_hillier_unpitied_theobromine', 'feature_perigean_bewitching_thruster']\n",
      "['target', 'target_nomi_20', 'target_nomi_60', 'target_jerome_20', 'target_jerome_60']\n",
      "\r"
     ]
    }
   ],
   "source": [
    "#what features are available\n",
    "features = [c for c in train_data if c.startswith('feature')]\n",
    "print(features[:5])\n",
    "targets = [c for c in train_data if c.startswith('target')]\n",
    "target = 'target'\n",
    "print(targets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301247, 1073)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "sub_sampl_td = train_data[train_data.era.isin([i for i in range(1, 574, 8)])]\n",
    "sub_sampl_td.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "sub2 = train_data[train_data.era.isin(range(3, 574, 8))]\n",
    "sub3 = train_data[train_data.era.isin(range(5, 574, 8))]\n",
    "sub4 = train_data[train_data.era.isin(range(7, 574, 8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "X = sub_sampl_td[features]\n",
    "y = sub_sampl_td[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = linear_model.LinearRegression()\n",
    "model2.fit(sub2[features], sub2[target])\n",
    "model2.fit(sub3[features], sub3[target])\n",
    "model2.fit(sub4[features], sub4[target])\n",
    "\n",
    "y_pred = model2.predict(sub_sampl_td[features])\n",
    "y_actual = sub_sampl_td[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.34140007e-02, 5.94429802e-04],\n",
       "       [5.34140007e-02, 1.00000000e+00, 7.65295876e-04],\n",
       "       [5.94429802e-04, 7.65295876e-04, 1.00000000e+00]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "rand = np.random.rand(len(y_actual))\n",
    "np.corrcoef([y_pred, y_actual, rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(sub2[features])\n",
    "y_actual = sub2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "rand = np.random.rand(len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.05530899,  0.00794163,  0.00156338],\n",
       "       [ 0.05530899,  1.        , -0.00153283,  0.00168634],\n",
       "       [ 0.00794163, -0.00153283,  1.        ,  0.00185062],\n",
       "       [ 0.00156338,  0.00168634,  0.00185062,  1.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "np.corrcoef([y_pred, y_actual, sub2[features].iloc[:,1], rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 9.00049793e-04],\n",
       "       [9.00049793e-04, 1.00000000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "np.corrcoef(y, X.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditions on tournament data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 16:43:32,883 INFO numerapi.utils: target file already exists\n",
      "2022-02-27 16:43:32,922 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# tour_data = pd.read_parquet('numerai_tournament_data.parquet')\n",
    "napi = NumerAPI()\n",
    "napi.download_dataset('numerai_tournament_data.parquet', 'numerai_tournament_data.parquet')\n",
    "tour_data = pd.read_parquet('numerai_tournament_data.parquet')\n",
    "y_tour_pred = model2.predict(tour_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_dichasial_hammier_spawner</th>\n",
       "      <th>feature_rheumy_epistemic_prancer</th>\n",
       "      <th>feature_pert_performative_hormuz</th>\n",
       "      <th>feature_hillier_unpitied_theobromine</th>\n",
       "      <th>feature_perigean_bewitching_thruster</th>\n",
       "      <th>feature_renegade_undomestic_milord</th>\n",
       "      <th>feature_koranic_rude_corf</th>\n",
       "      <th>feature_demisable_expiring_millepede</th>\n",
       "      <th>...</th>\n",
       "      <th>target_paul_20</th>\n",
       "      <th>target_paul_60</th>\n",
       "      <th>target_george_20</th>\n",
       "      <th>target_george_60</th>\n",
       "      <th>target_william_20</th>\n",
       "      <th>target_william_60</th>\n",
       "      <th>target_arthur_20</th>\n",
       "      <th>target_arthur_60</th>\n",
       "      <th>target_thomas_20</th>\n",
       "      <th>target_thomas_60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n000101811a8a843</th>\n",
       "      <td>0575</td>\n",
       "      <td>test</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n001e1318d5072ac</th>\n",
       "      <td>0575</td>\n",
       "      <td>test</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002a9c5ab785cbb</th>\n",
       "      <td>0575</td>\n",
       "      <td>test</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002ccf6d0e8c5ad</th>\n",
       "      <td>0575</td>\n",
       "      <td>test</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0051ab821295c29</th>\n",
       "      <td>0575</td>\n",
       "      <td>test</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   era data_type  feature_dichasial_hammier_spawner  \\\n",
       "id                                                                    \n",
       "n000101811a8a843  0575      test                               0.50   \n",
       "n001e1318d5072ac  0575      test                               0.25   \n",
       "n002a9c5ab785cbb  0575      test                               0.25   \n",
       "n002ccf6d0e8c5ad  0575      test                               0.50   \n",
       "n0051ab821295c29  0575      test                               0.50   \n",
       "\n",
       "                  feature_rheumy_epistemic_prancer  \\\n",
       "id                                                   \n",
       "n000101811a8a843                               0.0   \n",
       "n001e1318d5072ac                               1.0   \n",
       "n002a9c5ab785cbb                               0.5   \n",
       "n002ccf6d0e8c5ad                               1.0   \n",
       "n0051ab821295c29                               0.0   \n",
       "\n",
       "                  feature_pert_performative_hormuz  \\\n",
       "id                                                   \n",
       "n000101811a8a843                               1.0   \n",
       "n001e1318d5072ac                               0.5   \n",
       "n002a9c5ab785cbb                               0.5   \n",
       "n002ccf6d0e8c5ad                               0.5   \n",
       "n0051ab821295c29                               0.0   \n",
       "\n",
       "                  feature_hillier_unpitied_theobromine  \\\n",
       "id                                                       \n",
       "n000101811a8a843                                  0.00   \n",
       "n001e1318d5072ac                                  0.50   \n",
       "n002a9c5ab785cbb                                  0.75   \n",
       "n002ccf6d0e8c5ad                                  1.00   \n",
       "n0051ab821295c29                                  0.25   \n",
       "\n",
       "                  feature_perigean_bewitching_thruster  \\\n",
       "id                                                       \n",
       "n000101811a8a843                                  0.75   \n",
       "n001e1318d5072ac                                  0.25   \n",
       "n002a9c5ab785cbb                                  0.25   \n",
       "n002ccf6d0e8c5ad                                  0.50   \n",
       "n0051ab821295c29                                  0.00   \n",
       "\n",
       "                  feature_renegade_undomestic_milord  \\\n",
       "id                                                     \n",
       "n000101811a8a843                                0.00   \n",
       "n001e1318d5072ac                                0.75   \n",
       "n002a9c5ab785cbb                                0.25   \n",
       "n002ccf6d0e8c5ad                                1.00   \n",
       "n0051ab821295c29                                1.00   \n",
       "\n",
       "                  feature_koranic_rude_corf  \\\n",
       "id                                            \n",
       "n000101811a8a843                       1.00   \n",
       "n001e1318d5072ac                       0.75   \n",
       "n002a9c5ab785cbb                       0.75   \n",
       "n002ccf6d0e8c5ad                       0.75   \n",
       "n0051ab821295c29                       0.50   \n",
       "\n",
       "                  feature_demisable_expiring_millepede  ...  target_paul_20  \\\n",
       "id                                                      ...                   \n",
       "n000101811a8a843                                  0.25  ...             NaN   \n",
       "n001e1318d5072ac                                  0.00  ...             NaN   \n",
       "n002a9c5ab785cbb                                  0.00  ...             NaN   \n",
       "n002ccf6d0e8c5ad                                  0.50  ...             NaN   \n",
       "n0051ab821295c29                                  0.25  ...             NaN   \n",
       "\n",
       "                  target_paul_60  target_george_20  target_george_60  \\\n",
       "id                                                                     \n",
       "n000101811a8a843             NaN               NaN               NaN   \n",
       "n001e1318d5072ac             NaN               NaN               NaN   \n",
       "n002a9c5ab785cbb             NaN               NaN               NaN   \n",
       "n002ccf6d0e8c5ad             NaN               NaN               NaN   \n",
       "n0051ab821295c29             NaN               NaN               NaN   \n",
       "\n",
       "                  target_william_20  target_william_60  target_arthur_20  \\\n",
       "id                                                                         \n",
       "n000101811a8a843                NaN                NaN               NaN   \n",
       "n001e1318d5072ac                NaN                NaN               NaN   \n",
       "n002a9c5ab785cbb                NaN                NaN               NaN   \n",
       "n002ccf6d0e8c5ad                NaN                NaN               NaN   \n",
       "n0051ab821295c29                NaN                NaN               NaN   \n",
       "\n",
       "                  target_arthur_60  target_thomas_20  target_thomas_60  \n",
       "id                                                                      \n",
       "n000101811a8a843               NaN               NaN               NaN  \n",
       "n001e1318d5072ac               NaN               NaN               NaN  \n",
       "n002a9c5ab785cbb               NaN               NaN               NaN  \n",
       "n002ccf6d0e8c5ad               NaN               NaN               NaN  \n",
       "n0051ab821295c29               NaN               NaN               NaN  \n",
       "\n",
       "[5 rows x 1073 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "tour_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/at/atenv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-511fcd38d811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtour_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tour_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/at/atenv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/at/atenv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "pred_df = tour_data[\"id\"].to_frame()\n",
    "pred_df['prediction'] = y_tour_pred\n",
    "pred_df.head()\n",
    "pred_df.to_csv('pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n000101811a8a843</th>\n",
       "      <td>n000101811a8a843</td>\n",
       "      <td>0.493799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n001e1318d5072ac</th>\n",
       "      <td>n001e1318d5072ac</td>\n",
       "      <td>0.534890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002a9c5ab785cbb</th>\n",
       "      <td>n002a9c5ab785cbb</td>\n",
       "      <td>0.496155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002ccf6d0e8c5ad</th>\n",
       "      <td>n002ccf6d0e8c5ad</td>\n",
       "      <td>0.497578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0051ab821295c29</th>\n",
       "      <td>n0051ab821295c29</td>\n",
       "      <td>0.508729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  prediction\n",
       "id                                            \n",
       "n000101811a8a843  n000101811a8a843    0.493799\n",
       "n001e1318d5072ac  n001e1318d5072ac    0.534890\n",
       "n002a9c5ab785cbb  n002a9c5ab785cbb    0.496155\n",
       "n002ccf6d0e8c5ad  n002ccf6d0e8c5ad    0.497578\n",
       "n0051ab821295c29  n0051ab821295c29    0.508729"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Get your API keys and model_id from https://numer.ai/notebook\n",
    "public_id = \"LQKTEJFA2UZ4ERFNSXVUNJUEDWZEXPYI\"\n",
    "secret_key = \"KKMAFRZSIRYWKDLOJ6VLGJYLIPNKKYHVY7ALMVK37CH52II5JC7LIHAAE4VCI5PV\"\n",
    "model_id = \"d537b445-b274-43b6-8687-a276f182ed33\"\n",
    "napi = NumerAPI(public_id=public_id, secret_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 17:28:11,368 INFO numerapi.base_api: uploading predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Upload your predictions\n",
    "submission_id = napi.upload_predictions(\"pred.csv\", model_id=model_id, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method upload_predictions in module numerapi.numerapi:\n",
      "\n",
      "upload_predictions(file_path: str = 'predictions.csv', tournament: int = 8, model_id: str = None, df: pandas.core.frame.DataFrame = None, version: int = 1) -> str method of numerapi.numerapi.NumerAPI instance\n",
      "    Upload predictions from file.\n",
      "    Will read TRIGGER_ID from the environment if this model is enabled with\n",
      "    a Numerai Compute cluster setup by Numerai CLI.\n",
      "    \n",
      "    Args:\n",
      "        file_path (str): CSV file with predictions that will get uploaded\n",
      "        tournament (int): ID of the tournament (optional, defaults to 8)\n",
      "            -- DEPRECATED there is only one tournament nowadays\n",
      "        model_id (str): Target model UUID (required for accounts with\n",
      "            multiple models)\n",
      "        df (pandas.DataFrame): pandas DataFrame to upload, if function is\n",
      "            given df and file_path, df will be uploaded.\n",
      "        version (int): Version of create_submissions to use (optional,\n",
      "            defaults to 1)\n",
      "            Set to 1 to submit predictions for the 310 features dataset\n",
      "            Set to 2 to submit predictions for the 1050+ features dataset\n",
      "    \n",
      "    Returns:\n",
      "        str: submission_id\n",
      "    \n",
      "    Example:\n",
      "        >>> api = NumerAPI(secret_key=\"..\", public_id=\"..\")\n",
      "        >>> model_id = api.get_models()['uuazed']\n",
      "        >>> api.upload_predictions(\"prediction.cvs\", model_id=model_id)\n",
      "        '93c46857-fed9-4594-981e-82db2b358daf'\n",
      "        >>> # upload from pandas DataFrame directly:\n",
      "        >>> api.upload_predictions(df=predictions_df, model_id=model_id)\n",
      "\n",
      "\r"
     ]
    }
   ],
   "source": [
    "help(napi.upload_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "val_data = pd.read_parquet('numerai_validation_data.parquet')\n",
    "y_val_pred = model2.predict(val_data[features])\n",
    "\n",
    "pred_df = val_data.index.to_frame()\n",
    "pred_df['prediction'] = y_val_pred\n",
    "pred_df.head()\n",
    "pred_df.to_csv('pred_val.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n000101811a8a843</th>\n",
       "      <td>n000101811a8a843</td>\n",
       "      <td>0.493799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n001e1318d5072ac</th>\n",
       "      <td>n001e1318d5072ac</td>\n",
       "      <td>0.534890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002a9c5ab785cbb</th>\n",
       "      <td>n002a9c5ab785cbb</td>\n",
       "      <td>0.496155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n002ccf6d0e8c5ad</th>\n",
       "      <td>n002ccf6d0e8c5ad</td>\n",
       "      <td>0.497578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0051ab821295c29</th>\n",
       "      <td>n0051ab821295c29</td>\n",
       "      <td>0.508729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  prediction\n",
       "id                                            \n",
       "n000101811a8a843  n000101811a8a843    0.493799\n",
       "n001e1318d5072ac  n001e1318d5072ac    0.534890\n",
       "n002a9c5ab785cbb  n002a9c5ab785cbb    0.496155\n",
       "n002ccf6d0e8c5ad  n002ccf6d0e8c5ad    0.497578\n",
       "n0051ab821295c29  n0051ab821295c29    0.508729"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def max_con(b,c):\n",
    "    return np.corrcoef(b,c)[0,1]\n",
    "#     con = 0\n",
    "#     m = 0\n",
    "#     for j in range(len(b)):\n",
    "#         if b[j]!=c[j]:\n",
    "#             con=0\n",
    "#         else:\n",
    "#             con+=1\n",
    "#         if con>m:\n",
    "#             m=con\n",
    "#     return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "l1 = len(sub2[target])\n",
    "l2 = len(sub3[target])\n",
    "# i=0\n",
    "a = np.array(\n",
    "            [\n",
    "                max_con(sub2[target].iloc[i:].values, sub3[target].iloc[:l1-i].values) \n",
    "                for i in range(0, int(l1/2), int(l1/100))\n",
    "            ]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.65365753e-05],\n",
       "       [1.65365753e-05, 1.00000000e+00]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "np.corrcoef(sub2[target], sub3[target].iloc[:l1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "\r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "b = sub2[target].iloc[i:].values\n",
    "c = sub3[target].iloc[:l1-i].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
